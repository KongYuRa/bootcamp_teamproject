{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"langchain\")\n",
    "openai.api_key = os.environ.get(\"MY_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_json_data(json_files):\n",
    "    \"\"\"\n",
    "    여러 JSON 파일을 읽고 데이터를 통합한 후 특정 형식의 문자열 리스트로 반환\n",
    "\n",
    "    Parameters:\n",
    "        json_files (list): JSON 파일 경로 리스트\n",
    "\n",
    "    Returns:\n",
    "        list: 파일 데이터에서 'title'과 'content'를 읽어 특정 형식으로 변환한 리스트\n",
    "    \"\"\"\n",
    "    all_json_data = []\n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                all_json_data.extend(data)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: 파일을 찾을 수 없습니다 - {file_path}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: JSON 파일 형식이 잘못되었습니다 - {file_path}\")\n",
    "\n",
    "    # 'title'과 'content'를 읽어 특정 형식으로 반환\n",
    "    title = [item.get('title', 'N/A') for item in all_json_data]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def load_vector_store(db_name: str, DB_PATH):\n",
    "        \"\"\"\n",
    "        로컬에 저장된 크로마 db를 불러옴\n",
    "\n",
    "        Parameters:\n",
    "            db_name : db 생성시 설정한 이름\n",
    "            DB_PATH : db 경로\n",
    "        Returns:\n",
    "            Chroma 객체\n",
    "        \"\"\"\n",
    "        return Chroma(\n",
    "        collection_name=db_name,\n",
    "        persist_directory=DB_PATH,\n",
    "        embedding_function=OpenAIEmbeddings(\n",
    "            model=\"text-embedding-ada-002\", api_key=openai.api_key\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋에서 제목만 추출\n",
    "- 제목 리스트로 무작위 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = ['./documents/filtered_unsolved_cases.json', './documents/korea_crime.json']\n",
    "titles = title_json_data(json_files)\n",
    "sample_titles = titles[0:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미리 제작된 스크립트가 저장되어 있는 db 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './db/script_db'\n",
    "db_name = 'script_db'\n",
    "script_db = load_vector_store(db_name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 제목: 정인숙 피살사건\n",
      "\n",
      "# 프롤로그 1: 사건을 다룬 미디어\n",
      "- 2010년 3월 20일, SBS TV에서 방영된 프로그램은 정인숙 피살사건의 실체를 추적하는 내용을 담고 있다. 이 프로그램은 사건의 복잡성과 미해결 상태를 조명하며, 당시 수사 기록과 현장 감식 자료를 공개하여 새로운 시각을 제공하였다.\n",
      "\n",
      "# 프롤로그 2: 사건의 배경\n",
      "- 정인숙 피살사건은 1970년 3월 17일 서울에서 발생한 교통사고로 위장된 살인 사건이다. 이 사건은 고급 호스티스에서 일하던 정인숙이 총에 맞아 사망한 사건으로, 그녀의 형 정종욱이 부상을 입고 생존하였다. 사건은 정인숙의 자녀 아버지가 고위 정치인이라는 점에서 정부의 개입 의혹을 불러일으켰다.\n",
      "\n",
      "# 프롤로그 3: 정인숙의 인물상\n",
      "- 정인숙은 1945년 1월 1일에 태어나 고위 공직자 가문에서 자랐다. 그녀는 대학을 중퇴하고 고급 호스티스로 일하며 사회의 주목을 받았다. 정인숙은 당시 26세였고, 3세 아들을 두고 있었다. 그녀의 소지품에서 고위 인사들의 명함이 발견되었고, 숨겨진 자녀에 대한 소문이 돌았다.\n",
      "\n",
      "# 전개 1: 사건의 역사적 배경\n",
      "- 1970년대 초반, 한국은 정치적 불안정과 사회적 갈등이 심화되던 시기였다. 이 시기에 발생한 정인숙 피살사건은 고위층의 부패와 권력 남용에 대한 의혹을 불러일으켰다. 사건은 당시 사회의 불신과 불안감을 더욱 부각시켰다.\n",
      "\n",
      "# 전개 2: 정인숙의 개인사\n",
      "- 정인숙은 고위 공무원의 딸로 태어나 여러 명의 친오빠가 있었다. 그녀는 고급 요정에서 호스티스로 일하며, 당시 한일회담이 이루어진 선운각 등에서 활동하였다. 정인숙은 당시 정부의 유력 인사와의 관계로 인해 사회적 스캔들의 중심에 서게 되었다.\n",
      "\n",
      "# 전개 3: 사건의 시작\n",
      "- 1970년 3월 17일 밤 11시경, 서울 마포구 합정동 절두산 근처 도로에서 정인숙과 그녀의 형 정종욱이 탄 검은색 코로나 승용차가 멈춰 서 있었다. 이때 정인숙은 총에 맞아 사망하고, 정종욱은 부상을 입었다. 사건은 교통사고로 위장되었으나, 이후 총격 사건으로 밝혀졌다.\n",
      "\n",
      "# 발전 1: 사건의 상황과 정종욱의 행동\n",
      "- 정종욱은 사건 발생 후, 지나가던 택시기사에게 도움을 요청하여 구조되었다. 그는 정인숙의 문란한 행실을 지적하며 갈등이 생겼고, 가족의 명예를 지키기 위해 그녀를 암살하고 강도로 위장하려 했다는 주장이 제기되었다.\n",
      "\n",
      "# 발전 2: 사건의 영향\n",
      "- 사건은 한국 사회에 큰 충격을 주었고, 고위층의 부패와 권력 남용에 대한 의혹을 불러일으켰다. 신민당은 이 사건의 배후로 정부 고위층의 개입 의혹을 제기하였으나, 사건은 유야무야 묻혀져 미제로 남아있다.\n",
      "\n",
      "# 발전 3: 대중의 반응\n",
      "- 사건 발생 후, 언론은 정인숙의 숨겨진 아들에 대한 소문과 그녀의 고위층 인사들과의 관계를 집중 보도하였다. 대중은 사건의 진상에 대한 궁금증과 불신을 가지게 되었고, 정종욱의 자백에 대한 의혹이 제기되었다.\n",
      "\n",
      "# 클라이맥스 1: 사건의 확대\n",
      "- 사건의 진상은 여전히 불투명했으며, 정종욱이 범인으로 지목되었으나 그의 자백 외에 증거는 없었다. 사건은 권력자들의 압력으로 인해 흐지부지되었고, 정종욱이 사용한 권총은 발견되지 않았다.\n",
      "\n",
      "# 클라이맥스 2: 갈등과 드라마틱한 전개\n",
      "- 정종욱은 19년의 형기를 마치고 출옥한 후, \"동생과 관계했던 고위층이 뒤를 봐준다고 했다는 아버지의 회유로 거짓자백을 했을 뿐\"이라고 주장하였다. 그는 사건의 진범에 대한 의혹이 여전히 남아있다고 강조하였다.\n",
      "\n",
      "# 클라이맥스 3: 사건의 후폭풍\n",
      "- 사건은 한국 현대사의 미스터리 사건으로 남아 있으며, 정인숙의 죽음은 권력자들의 부패와 관련된 주장들을 불러일으켰다. 대중은 사건의 진실을 알고 싶어 하였고, 정종욱은 억울함을 호소하였다.\n",
      "\n",
      "# 결말: 사건의 해결\n",
      "- 정인숙 피살사건은 여전히 미해결 상태로 남아 있으며, 고위층의 부패와 권력 남용에 대한 의혹은 계속되고 있다. 사건의 진상은 밝혀지지 않았고, 정종욱의 주장과 대중의 의혹은 여전히 논란이 되고 있다.\n",
      "\n",
      "# 에필로그: 사건의 메시지\n",
      "- 정인숙 피살사건은 한국 사회에서 권력과 부패, 그리고 개인의 비극이 얽힌 복잡한 사건으로 남아있다. 이 사건은 권력자들의 부패와 그로 인한 피해자들의 고통을 상기시키며, 사회의 불신과 불안을 더욱 부각시켰다. 사건은 여전히 대중의 관심을 끌고 있으며, 진실을 찾기 위한 노력은 계속되고 있다.\n"
     ]
    }
   ],
   "source": [
    "rt = script_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "print(rt.invoke('정인숙')[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검증 LLM\n",
    "- 사용자의 질문과 RAG를 통해 검색된 스크립트의 연관성을 검증\n",
    "- 스크립트의 전체 맥락을 고려하여 사용자가 찾는 이야기가 맞는지 판단\n",
    "- 정수형 점수 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(query, db):\n",
    "    \"\"\"\n",
    "    db에서 찾아온 스크립트가 적절한지 판단하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        query : 사용자 입력\n",
    "        db : 스크립트가 저장된 db\n",
    "    Returns:\n",
    "        연관 정도 점수\n",
    "        스크립트 : 연관 정도가 적절한 경우\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        api_key=openai.api_key,\n",
    "        max_tokens=100,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    script_retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "    script = script_retriever.invoke(query)[0].page_content\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    persona : relavence check machine\n",
    "    **return only integer score**\n",
    "    1. extract subject of script\n",
    "    2. check relavence between query and subject\n",
    "    3. calculate elaborate score \n",
    "    4. maximum '100', minimum '0', \n",
    "    5. increas by '5'\n",
    "    6. sample is about conversation\n",
    "    <sample>\n",
    "    script : 'title : 강다니엘 이모 사건, content : 나 아는사람 강다니엘 닮은 이모가 다시보게되는게 다시 그때처럼 안닮게 엄마보면 느껴지는걸수도 있는거임?'\n",
    "\n",
    "    query : '사건'\n",
    "    ai : '10'\n",
    "\n",
    "    query : '이모'\n",
    "    ai : '25'\n",
    "\n",
    "    query : '이모 사건'\n",
    "    ai : '80'\n",
    "\n",
    "    query : '강다니엘 사건'\n",
    "    ai : '85'\n",
    "\n",
    "    query : '강다니엘 이모'\n",
    "    ai : '95'\n",
    "    </sample>\n",
    "\n",
    "    <query>\n",
    "    {query}\n",
    "    </query>\n",
    "\n",
    "    <script>\n",
    "    {script}\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    score = chain.invoke({\"query\": query, 'script' : script})\n",
    "    if not score : return [0, 'N/A']\n",
    "    return [int(score), script]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트 수정\n",
    "#### 기존\n",
    "- 사용자 입력마다 스크립트를 불러옴\n",
    "- 대부분 대화 메모리로 맥락을 유지하여 같은 스크립트를 불러옴\n",
    "- 일정 확률로 다른 스크립트를 불러오는 문제 발생\n",
    "\n",
    "### 수정 \n",
    "- 검증 LLM 으로 검증한 스크립트로 고정\n",
    "- `RunnableMap` : 인자 설정이 자유로운 chain 형식\n",
    "- 일단 시작된 이야기는 그대로 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "openai.api_key = os.environ.get(\"MY_OPENAI_API_KEY\")\n",
    "\n",
    "def chain_maker(script):\n",
    "    \"\"\"\n",
    "    스크립트를 바탕으로 대화를 이어나가는 llm chain 생성\n",
    "\n",
    "    Parameters:\n",
    "        script : 선택된 스크립트\n",
    "    Returns:\n",
    "        llm chain\n",
    "     \"\"\"\n",
    "    prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    persona : story teller\n",
    "    language : only korean\n",
    "    tell dramatic story like talking to friend,\n",
    "    speak informally,\n",
    "    progress chapter by chapter,\n",
    "    **hide header like '###'**,\n",
    "    start chapter with interesting question,\n",
    "    wait user answer,\n",
    "    give reaction to answer,\n",
    "    do not use same reaction or same question\n",
    "    \n",
    "    # script\n",
    "    {script}\n",
    "\n",
    "    #Previous Chat History:\n",
    "    {chat_history}\n",
    "\n",
    "    #Question: \n",
    "    {question} \n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key= openai.api_key, temperature=0.3)\n",
    "\n",
    "    # 단계 8: 체인(Chain) 생성\n",
    "    chain = RunnableMap(\n",
    "        {\n",
    "            \"script\": lambda inputs: script,  # script는 고정값으로 전달\n",
    "            \"question\": itemgetter(\"question\"),  # 입력에서 question 추출\n",
    "            \"chat_history\": itemgetter(\"chat_history\"),  # 입력에서 chat_history 추출\n",
    "        }\n",
    "    ) | prompt | llm | StrOutputParser()\n",
    "    return chain\n",
    "\n",
    "def history_chain(chain, memory_store : dict):\n",
    "    \"\"\"\n",
    "    맥락을 유지하면 대화하는 chain 생성\n",
    "\n",
    "    Parameters:\n",
    "        chain : script 를 찾아 답변하는 chain\n",
    "        memory_store : 대화의 맥락이 저장될 공간\n",
    "    Returns:\n",
    "        memory history chain\n",
    "     \"\"\"\n",
    "    def get_session_history(session_ids):\n",
    "        print(f\"[대화 세션ID]: {session_ids}\")\n",
    "        if session_ids not in memory_store:  # 세션 ID가 store에 없는 경우\n",
    "            # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "            memory_store[session_ids] = ChatMessageHistory()\n",
    "        return memory_store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "    # 대화를 기록하는 RAG 체인 생성\n",
    "    rag_with_history = RunnableWithMessageHistory(\n",
    "        chain,\n",
    "        get_session_history,  # 세션 기록을 가져오는 함수\n",
    "        input_messages_key=\"question\",  # 사용자의 질문이 템플릿 변수에 들어갈 key\n",
    "        history_messages_key=\"chat_history\",  # 기록 메시지의 키\n",
    "    )\n",
    "    return rag_with_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "def documents_filter(SPLITS):\n",
    "    \"\"\"\n",
    "    분할된 데이터에서 불필요한 데이터를 제거하고 하나로 결합\n",
    "    ConversationSummaryMemory에 이전 내용을 요약하여 저장\n",
    "    아전 내용과 대조해서 불필요한 데이터 구분\n",
    "\n",
    "    Parameters:\n",
    "        SPLITS: 분할된 텍스트 데이터 : Document\n",
    "\n",
    "    Returns:\n",
    "        텍스트 데이터\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                api_key=openai.api_key,\n",
    "                max_tokens=1000,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "    summaries = []\n",
    "    memory = ConversationSummaryMemory(\n",
    "        llm=llm, return_messages=True)\n",
    "    \n",
    "    count = 0\n",
    "    for SPLIT in SPLITS:\n",
    "        SPLIT = SPLIT.page_content\n",
    "\n",
    "        try:\n",
    "            context = memory.load_memory_variables({})[\"history\"]\n",
    "            prompt = ChatPromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                persona : documents filter\n",
    "                language : only in korean\n",
    "                extract the parts related to the context and ignore the rest,\n",
    "                write blanck if it's not relevant,\n",
    "                \n",
    "                <context>\n",
    "                {context}\n",
    "                </context>\n",
    "                \n",
    "                <docs>\n",
    "                {SPLIT}\n",
    "                </docs>\n",
    "                \"\"\"\n",
    "            )\n",
    "            chain = prompt | llm | StrOutputParser()\n",
    "            summary = chain.invoke({\"SPLIT\": SPLIT, 'context' : context})\n",
    "            memory.save_context({\"input\": f'summary # {count}'}, {\"output\": summary})\n",
    "            summaries.append(summary)\n",
    "            count+=1\n",
    "\n",
    "        except Exception as e:\n",
    "            # 오류 처리: 만약 API 호출 중에 문제가 발생하면 오류 메시지 추가\n",
    "            print(f\"Error summarizing document: {e}\")\n",
    "            summaries.append(f\"Error summarizing document: {e}\")\n",
    "\n",
    "    return \"\".join(summaries)\n",
    "\n",
    "def generate_script(summaries):\n",
    "    \"\"\"\n",
    "    대화 LLM이 전달할 이야기의 대본 생성\n",
    "\n",
    "    Parameters:\n",
    "        summaries: 필터링된 텍스트 데이터\n",
    "\n",
    "    Returns:\n",
    "        텍스트 데이터\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        api_key=openai.api_key,\n",
    "        max_tokens=5000,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    persona = script writer\n",
    "    language = only in korean\n",
    "    least 3000 tokens\n",
    "    use input,\n",
    "    refer to sample,\n",
    "    write about time, character, event,\n",
    "    write only fact\n",
    "    ignore the mere listing of facts and write N/A\n",
    " \n",
    "    <sample>\n",
    "    # title : title of script\n",
    "    # prologue 1 : song, movie, book, show about subject\n",
    "    - coontent :\n",
    "    # prologue 2 : explain about subject\n",
    "    - coontent :\n",
    "    # prologue 3 : explain about character\n",
    "    - coontent :\n",
    "    # exposition 1 : historical background of subject\n",
    "    - coontent :\n",
    "    # exposition 2 : history of character\n",
    "    - coontent :\n",
    "    # exposition 3 : beginning of event\n",
    "    - coontent :\n",
    "    # development 1 : situation, action, static of character\n",
    "    - coontent :\n",
    "    # development 2 : influence of event\n",
    "    - coontent :\n",
    "    # development 3 : reaction of people\n",
    "    - coontent :\n",
    "    # climax 1 : event and effect bigger\n",
    "    - coontent :\n",
    "    # climax 2 : dramatic action, conflict\n",
    "    - coontent :\n",
    "    # climax 3 : falling Action\n",
    "    - coontent :\n",
    "    # denouement : resolution\n",
    "    - coontent :\n",
    "    # epilogue : message, remaining\n",
    "    - coontent :\n",
    "    </sample>\n",
    "\n",
    "    <input>\n",
    "    {summaries}\n",
    "    </input>\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    script = chain.invoke({\"summaries\": summaries})\n",
    "    return script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자가 입력한 정보로 새로운 스크립트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def script_maker(INPUT : str):\n",
    "  print(\"다소 시간이 소요될 수 있습니다.\")\n",
    "  text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1000, chunk_overlap=100\n",
    "        )\n",
    "  if INPUT.startswith(\"http\"):\n",
    "        url = INPUT\n",
    "        web_docs = WebBaseLoader(url).load()\n",
    "        if web_docs[0].metadata['title'] : title = web_docs[0].metadata['title']\n",
    "        else : title = ''\n",
    "        docs = f\"title : {title} \\n\\n\" + web_docs[0].page_content\n",
    "  else:\n",
    "        docs= str(INPUT)\n",
    "  documents = [Document(page_content=docs)]\n",
    "  SPLITS = text_splitter.split_documents(documents)\n",
    "  refined = documents_filter(SPLITS)\n",
    "  return generate_script(refined)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://namu.wiki/w/77246%20위조지폐%20유통사건'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검증 LLM이 반환안 점수에 따라 진행 결정\n",
    "- 80 점 미만 : 종료, 재시작, 생성\n",
    "- 80-95점 : 자세한 설명 요구\n",
    "- 95점 : 그대로 진행\n",
    "\n",
    "#### 생성\n",
    "- 스크립트 생성 함수로 새로운 스크립트 생성\n",
    "- 스크립트 db에 저장\n",
    "- 다시 답변 요구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "777\n",
      "85\n",
      "더 자세히 이야기 해주세요\n",
      "================================\n",
      "777 항공편\n",
      "85\n",
      "더 자세히 이야기 해주세요\n",
      "================================\n",
      "대한항공 77\n",
      "85\n",
      "더 자세히 이야기 해주세요\n",
      "================================\n",
      "대한항공 777편\n",
      "85\n",
      "더 자세히 이야기 해주세요\n",
      "================================\n",
      "대한항공 격추\n",
      "95\n",
      "[대화 세션ID]: test21\n",
      "\n",
      "답변:\n",
      "그 사건에 대해 들어본 적 있어? 대한항공 007편 격추 사건 말이야. 정말 충격적이고 드라마틱한 이야기야. 너는 어떻게 생각해?\n",
      "========================\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "while True:\n",
    "    print(\"================================\")\n",
    "    path = './db/script_db'\n",
    "    db_name = 'script_db'\n",
    "    script_db = load_vector_store(db_name, path)\n",
    "    query = input(\"어떤 이야기가 듣고 싶으신가요?\")\n",
    "    print(query)\n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        query = False\n",
    "        break\n",
    "    elif query is None or  \"아무거나\" in query.strip():\n",
    "        print(\"재미난 이야기를 가져오는 중...\")\n",
    "        choice = random.choice(sample_titles)\n",
    "        query = choice\n",
    "        print(choice)\n",
    "        break\n",
    "    \n",
    "    relavence = evaluator(query, script_db)\n",
    "    print(relavence[0])\n",
    "    if relavence[0] < 80: \n",
    "         print('모르는 이야기 입니다.', '종료 : exit', '다시 물어보기 : return', '생성하기 : create')\n",
    "         user_input = input('입력하세요.')\n",
    "         if user_input.lower() == \"exit\":\n",
    "            print(\"대화를 종료합니다.\")\n",
    "            query = False\n",
    "            break\n",
    "         elif user_input.lower() == \"return\":\n",
    "            continue\n",
    "         \n",
    "         elif user_input.lower() == \"create\":\n",
    "            text_input = input('URL 또는 텍스트를 입력해주세요.')\n",
    "            new_script = script_maker(text_input)\n",
    "            script_documents = [\n",
    "                Document(page_content=new_script),\n",
    "             ]\n",
    "            script_db.add_documents(script_documents)\n",
    "            script_db.persist()\n",
    "            print('생성이 완료되었습니다.', '다시 답변해주세요.')\n",
    "            continue\n",
    "         \n",
    "    elif relavence[0] < 95 and relavence[0] >= 80:\n",
    "        print(\"더 자세히 이야기 해주세요\")\n",
    "        continue\n",
    "    elif relavence[0] >= 95:\n",
    "        script = relavence[1]\n",
    "        break\n",
    "\n",
    "if query : \n",
    "    store ={}\n",
    "    chain = chain_maker(script)\n",
    "    h_chain = history_chain(chain, store)\n",
    "\n",
    "    response = h_chain.invoke(\n",
    "        # 질문 입력\n",
    "        {\"question\": query},\n",
    "        # 세션 ID 기준으로 대화를 기록합니다.\n",
    "        config={\"configurable\": {\"session_id\": \"test21\"}},\n",
    "    )\n",
    "    print(\"\\n답변:\")\n",
    "    print(response)\n",
    "\n",
    "    while True:\n",
    "        print(\"========================\")\n",
    "        query = input(\"반응을 입력하세요.\")\n",
    "        if query.lower() == \"exit\":\n",
    "                print(\"대화를 종료합니다.\")\n",
    "                break\n",
    "        response = h_chain.invoke(\n",
    "        # 질문 입력\n",
    "        {\"question\": query},\n",
    "        # 세션 ID 기준으로 대화를 기록합니다.\n",
    "        config={\"configurable\": {\"session_id\": \"test21\"}},\n",
    "    )\n",
    "        print(query)\n",
    "        print(\"\\n답변:\")\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 대한항공 격추\n",
      "AI: 그 사건에 대해 들어본 적 있어? 대한항공 007편 격추 사건 말이야. 정말 충격적이고 드라마틱한 이야기야. 너는 어떻게 생각해?\n"
     ]
    }
   ],
   "source": [
    "print(store['test21'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가할 사항\n",
    "- 다국어 기능\n",
    "- 코드 정리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
